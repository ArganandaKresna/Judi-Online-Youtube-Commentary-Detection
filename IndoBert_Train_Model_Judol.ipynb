{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f8fd87d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# @title [STEP 1] Instalasi Library\n",
    "%pip install transformers datasets accelerate scikit-learn pandas torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba7890d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# @title [STEP 2] Load Data & Split Train-Test\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# 1. Load Data\n",
    "try:\n",
    "    # Menggunakan dataset yang sudah diberi label\n",
    "    df = pd.read_csv('labeled_kandidat_spam.csv', sep=';')\n",
    "    \n",
    "    # Pastikan format label integer dan komentar string\n",
    "    df['label'] = df['label'].astype(int)\n",
    "    df['comment_text'] = df['comment_text'].astype(str)\n",
    "    \n",
    "    # 2. Split Data (80% Train, 20% Test)\n",
    "    # stratify=df['label'] penting agar rasio spam di train & test sama\n",
    "    train_df, test_df = train_test_split(df, test_size=0.2, random_state=42, stratify=df['label'])\n",
    "    \n",
    "    print(f\"Data Loaded! Total: {len(df)}\")\n",
    "    print(f\"Distibution Label: \\n{df['label'].value_counts()}\")\n",
    "    print(f\"Training Set: {len(train_df)} baris\")\n",
    "    print(f\"Testing Set: {len(test_df)} baris\")\n",
    "\n",
    "except FileNotFoundError:\n",
    "    print(\"‚ùå Error: File 'labeled_kandidat_spam.csv' tidak ditemukan. Pastikan file ada di folder yang sama!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fabf334",
   "metadata": {},
   "outputs": [],
   "source": [
    "# @title [STEP 3] Tokenisasi Data\n",
    "from transformers import BertTokenizer\n",
    "from datasets import Dataset\n",
    "\n",
    "# 1. Load Tokenizer IndoBERT\n",
    "PRETRAINED_MODEL = \"indobenchmark/indobert-base-p1\"\n",
    "tokenizer = BertTokenizer.from_pretrained(PRETRAINED_MODEL)\n",
    "\n",
    "# 2. Convert Pandas ke HuggingFace Dataset\n",
    "train_dataset = Dataset.from_pandas(train_df)\n",
    "test_dataset = Dataset.from_pandas(test_df)\n",
    "\n",
    "# 3. Fungsi Tokenisasi\n",
    "def tokenize_function(examples):\n",
    "    return tokenizer(\n",
    "        examples[\"comment_text\"],\n",
    "        padding=\"max_length\",\n",
    "        truncation=True,\n",
    "        max_length=128\n",
    "    )\n",
    "\n",
    "# 4. Terapkan ke Dataset\n",
    "print(\"‚öôÔ∏è Sedang melakukan tokenisasi...\")\n",
    "tokenized_train = train_dataset.map(tokenize_function, batched=True)\n",
    "tokenized_test = test_dataset.map(tokenize_function, batched=True)\n",
    "\n",
    "print(\"‚úÖ Tokenisasi Selesai!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb8f4d88",
   "metadata": {},
   "outputs": [],
   "source": [
    "# @title [STEP 4] Setup Model & Metrics\n",
    "from transformers import BertForSequenceClassification, TrainingArguments, Trainer\n",
    "from sklearn.metrics import accuracy_score, precision_recall_fscore_support\n",
    "import torch\n",
    "\n",
    "# 1. Load Model IndoBERT untuk Klasifikasi (2 Label: Spam/Not Spam)\n",
    "model = BertForSequenceClassification.from_pretrained(\n",
    "    PRETRAINED_MODEL,\n",
    "    num_labels=2\n",
    ")\n",
    "\n",
    "# 2. Fungsi Hitung Metrik\n",
    "def compute_metrics(pred):\n",
    "    labels = pred.label_ids\n",
    "    preds = pred.predictions.argmax(-1)\n",
    "\n",
    "    precision, recall, f1, _ = precision_recall_fscore_support(labels, preds, average='binary')\n",
    "    acc = accuracy_score(labels, preds)\n",
    "\n",
    "    return {\n",
    "        'accuracy': acc,\n",
    "        'f1': f1,\n",
    "        'precision': precision,\n",
    "        'recall': recall\n",
    "    }\n",
    "\n",
    "print(\"‚úÖ Model IndoBERT siap dilatih!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edf4296f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# @title [STEP 5] Eksekusi Training\n",
    "# Setting Training - Dioptimalkan untuk Akurasi > 85%\n",
    "training_args = TrainingArguments(\n",
    "    output_dir='./results',\n",
    "    num_train_epochs=15,             # Ditingkatkan menjadi 15 Epoch\n",
    "    per_device_train_batch_size=8,   # Batch size 8 untuk kestabilan lokal\n",
    "    per_device_eval_batch_size=8,\n",
    "    warmup_steps=100,\n",
    "    weight_decay=0.01,\n",
    "    logging_dir='./logs',\n",
    "    logging_steps=10,\n",
    "    eval_strategy=\"epoch\",\n",
    "    save_strategy=\"epoch\",\n",
    "    load_best_model_at_end=True,\n",
    "    metric_for_best_model=\"accuracy\", # Target utama adalah akurasi\n",
    "    learning_rate=3e-5,\n",
    ")\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=tokenized_train,\n",
    "    eval_dataset=tokenized_test,\n",
    "    compute_metrics=compute_metrics,\n",
    ")\n",
    "\n",
    "print(\"üöÄ MEMULAI TRAINING...\")\n",
    "trainer.train()\n",
    "print(\"üéâ TRAINING SELESAI!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2b0afb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# @title [STEP 6] Evaluasi Hasil Akhir\n",
    "print(\"üìä Mengevaluasi Model pada Data Test...\")\n",
    "results = trainer.evaluate()\n",
    "\n",
    "print(\"\\n\" + \"=\"*30)\n",
    "print(\"HASIL AKHIR:\")\n",
    "print(\"=\"*30)\n",
    "print(f\"üéØ Accuracy  : {results['eval_accuracy']:.4f}\")\n",
    "print(f\"‚≠ê F1-Score  : {results['eval_f1']:.4f}\")\n",
    "print(f\"üéØ Precision : {results['eval_precision']:.4f}\")\n",
    "print(f\"üì° Recall    : {results['eval_recall']:.4f}\")\n",
    "print(\"=\"*30)\n",
    "\n",
    "# Simpan Model Agar Bisa Dipakai Nanti\n",
    "if results['eval_accuracy'] >= 0.85:\n",
    "    model.save_pretrained(\"./indobert-spam-detection-final\")\n",
    "    tokenizer.save_pretrained(\"./indobert-spam-detection-final\")\n",
    "    print(\"‚úÖ Model berhasil mencapai target (>85%) dan tersimpan di folder 'indobert-spam-detection-final'\")\n",
    "else:\n",
    "    print(\"‚ö†Ô∏è Model belum mencapai target 85%. Coba tuning lagi.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c3d6831",
   "metadata": {},
   "outputs": [],
   "source": [
    "# @title [STEP 7] Demo Prediksi\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "\n",
    "def predict_spam(text):\n",
    "    inputs = tokenizer(text, return_tensors=\"pt\", padding=True, truncation=True, max_length=128)\n",
    "    inputs = {k: v.to(model.device) for k, v in inputs.items()}\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        outputs = model(**inputs)\n",
    "        probs = F.softmax(outputs.logits, dim=-1)\n",
    "        pred_idx = torch.argmax(probs).item()\n",
    "        confidence = probs[0][pred_idx].item()\n",
    "        \n",
    "    label_map = {0: \"AMAN\", 1: \"SPAM\"}\n",
    "    return label_map[pred_idx], confidence\n",
    "\n",
    "# Contoh Text\n",
    "test_texts = [\n",
    "    \"Wah keren banget videonya, semangat terus bang!\",\n",
    "    \"Info gacor maxwin hari ini klik link di bio\",\n",
    "    \"Halo kak, mau tanya cara install nya gimana?\",\n",
    "    \"Situs terpercaya deposit pulsa tanpa potongan\"\n",
    "]\n",
    "\n",
    "print(\"--- DEMO PREDIKSI ---\")\n",
    "for text in test_texts:\n",
    "    label, conf = predict_spam(text)\n",
    "    print(f\"Text: '{text}'\")\n",
    "    print(f\"Prediksi: {label} (Yakin: {conf:.2%})\\n\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
